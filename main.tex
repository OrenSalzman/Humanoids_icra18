%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai18.sty is the style file for IJCAI-18 (same as ijcai08.sty).
\usepackage{ijcai18}

% Use the postscript times font!
\usepackage{times}
\usepackage{xcolor}
\usepackage{soul}
\usepackage[utf8]{inputenc}
\usepackage[font=footnotesize]{caption}

\usepackage{savesym}
\usepackage{amsmath,amssymb,amsfonts}
%\usepackage[numbers]{natbib}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm,algorithmicx}
\usepackage{comment}
\usepackage{xspace}
\usepackage{scalerel}
\usepackage{xcolor}
%\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage[left]{showlabels}
\usepackage{multicol}
\usepackage{multirow}
\usepackage[bookmarks=true]{hyperref}
\usepackage{graphicx,subfigure}

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{	Online, interactive user guidance for \\
		high-dimensional, constrained motion planning }

\author{Fahad Islam, Oren Salzman and Maxim Likhachev% <-this % stops a space
  \thanks{Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA
    {\tt\small \{fi,osalzman\}@andrew.cmu.edu, maxim@cs.cmu.edu}
  }%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\input{macros.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
We consider the problem of planning a collision-free path for a high-dimensional robot.
Specifically, we suggest a planning framework where a motion-planning algorithm can obtain guidance from a user.
In contrast to existing approaches that try to speed up planning by incorporating experiences or demonstrations ahead of planning, 
we suggest to seek user guidance only when the planner identifies that it ceases to make significant progress towards the goal.
Guidance is provided in the form of an intermediate configuration~$\hat{q}$ which, is used to bias the planner to go through~$\hat{q}$.
We demonstrate our approach for the case where the planning algorithm is Multi-Heuristic \astar (\mhastar) and the robot is a 34-DOF humanoid.
We show that our approach allows to compute highly-constrained paths with little domain knowledge.
Without our approach, solving such problems requires carefully-crafting domain-dependent heuristics. 
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Intro
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{comment}

\section{Introduction}
\label{sec:intro}

Motion-planning is a fundamental problem in robotics that has been studied for over four \arxiv{decades~\cite{CBHKKLT05,L06,HSS17}}{decades~\cite{L06}}.
However, efficiently planning paths in high-dimensional, constrained spaces remains an ongoing challenge.
One approach to address this challenge is to incorporate user input to guide the motion-planning algorithm.
While there has been much work on planning using human demonstration 
\arxiv{(see, e.g.,~\cite{ACVB09,HS16,PHCL16,SHLA16,YA17}),}{(see, e.g.,~\cite{ACVB09,YA17}),}  
there has been far less research incorporating guidance as an interactive part of the planning~loop.

Broadly speaking, interactive planning has been typically used in the context of sampling-based motion-planning algorithms~\cite{L06}.
User guidance was employed by biasing the sampling scheme of the planner by having the user mark regions in the \emph{workspace} that should be avoided or 
%explored~\cite{DSJA14}.
\arxiv{explored~\cite{DSJA14,MTMKDC15,YPB15,RSL17}.}{explored~\cite{DSJA14,YPB15}.}
Alternatively, interactive devices such as~a 3D mouse or a haptic arm have been used to generate paths in~a (low-dimensional) configuration space. This path was then used by a planner to bias its 
%sampling domain~\cite{TFF12}.
\arxiv{sampling domain~\cite{BTFF16,FTF09,TFF12}.}{sampling domain~\cite{TFF12}.}
%Interestingly, in all the examples mentioned, an implicit assumption taken is that the user is dedicated to guide and interact with the planning algorithm.

We are interested in planning in high-dimensional, constrained spaces such as those encountered by a humanoid robot (see Fig.~\ref{fig:robot} and Sec.~\ref{sec:rel}).
In such settings, workspace regions often give little guidance to the planner due to the high dimension of the configuration space as well as the physical constraints of the robot.
Additionally, obtaining user guidance in the configuration space is extremely time consuming, even for expert users.
Thus,  while beneficial, user guidance should be employed scarcely.

\begin{figure}[tb]
  \centering
  	\includegraphics[trim={5cm 6cm 2.5cm 3.5cm},clip, width=0.35\textwidth]{fig/cover3.png}
  	\vspace{-2mm}
  \caption{
  Planning domain---Humanoid robot (top left) needs to plan a path in a challenging environment that involves circumventing obstacles and passing through narrow passages.
		% Planning domain---Humanoid robot needs to use the ladder or the staircase to reach the top while avoiding collision with the obstacles and adhering to the physical stability constraints.
%  	\vspace{-15mm}
}
   	\label{fig:robot}
\end{figure}

Our key insight is that carefully chosen individual configurations suggested by a user can be used to effectively guide the planner when in need.
Transforming this insight into a planning framework requires addressing three fundamental questions:

\begin{itemize}
	\item[\textbf{Q1.}] When should the planner ask the user for guidance?
	\item[\textbf{Q2.}] What form should the user's guidance take?
	\item[\textbf{Q3.}] How should the guidance be used by the planner?
\end{itemize}

Identifying \emph{when} to obtain guidance 
(Q1, Sec~\ref{sec:q1}) 
comes in stark contrast to existing approaches---we suggest to only employ user guidance when the planner \emph{identifies} that it ceases to make significant progress towards the goal.
%The specific type of guidance given 
%(Q2, Sec~\ref{sec:q2}),
%as previously mentioned,
%is configuration-space based and \emph{not} workspace-based. This deviation from previous work is due to our specific setting of high-dimensional, constrained systems.
Once obtained (Q2, Sec~\ref{sec:q2}), guidance is used to \emph{bias} the search algorithm towards regions that are likely to be beneficial (Q3, Sec~\ref{sec:q2}). 
The search algorithm now has the additional task of deducing how much to rely on the user-provided guidance.
It is worth emphasizing that this obtaining guidance does not require the user to understand the underlying search algorithm. 

% 
%In the following, we detail our planning framework (Sec.~\ref{sec:high}) and how it addresses each of these questions (Sec.~\ref{sec:q1}-\ref{sec:q3}).
%We then continue (Sec.~\ref{sec:eval}) to demonstrate its effectiveness in simulations and conclude by describing possible additional future work.



%\section{Related work}
%\label{sec:related}
%
We demonstrate our approach using search-based planning algorithms (see, e.g.,~\cite{CCL14}) that perform a systematic search guided by heuristic functions.
Specifically, we use multi-heuristic \astar (\mhastar)~\cite{ASNHL16,NAL15} which we detail in Sec.~\ref{sec:mha}.
We note that the formulation can, in general, be incorporated with any motion-planning algorithm, however showing its effectiveness on such algorithms is out of the scope of the paper.


%%(see discussion in Sec.~\ref{sec:future}) 
%it is especially suitable for search-based planning algorithms (see, e.g.,~\cite{CCL14}) that perform a systematic search guided by heuristic functions.
%Specifically, we demonstrate its effectiveness for the case where the motion-planning algorithm is multi-heuristic \astar (\mhastar)~\cite{ASNHL16,NAL15} which we detail in Sec.~\ref{sec:mha}.
%%MH\hastar is a search-based planning algorithm that takes in multiple, possibly inadmissible heuristic functions in addition to a single consistent admissible heuristic.
%%It uses them simultaneously to search the configuration space in an \astar-like manner that was shown to be both complete and ensures bounds on sub-optimality. 
%%This allows the search to efficiently combine the guiding powers of different heuristic functions. 
%



After describing our approach at high-level (Sec.~\ref{sec:high}) we demonstrate how it can be applied to the case of \mhastar (Sec.~\ref{sec:planning}).
We continue by showing the effectiveness of our planner (Sec.~\ref{sec:eval}).
Specifically, we show that this general approach allows to compute highly constrained motions for a spectrum of tasks including climbing stairs, walking under a bar, squeezing through a door and others, all with the same planner and the same heuristics.  
Without our approach, solving such problems requires the design of task-specific planners~\cite{KKKHKHAI04} and carefully-crafted domain-dependent heuristics
We conclude this paper with a discussion (Sec.~\ref{sec:future}).
%We conclude this paper with a discussion and an outline of possible future work (Sec.~\ref{sec:future}).


\section{Related work and algorithmic background}
\subsection{Motion planning for humanoid robots}
\label{sec:rel}
Humanoid robots, for which we demonstrate our approach, often have several dozens of degrees of freedom making planning a challenging task, especially when taking additional constraints into account such as stability and contact constraints.
One approach to plan the motion for such systems, is to use predefined, carefully chosen fixed gaits~\cite{KKKHKHAI04}. 
However, when the terrain is uneven, such planners are inadequate at computing stable motions~\cite{HBLHW08}.
Another approach is to reduce the search space by decomposing the degrees of freedom into functional groups such as locomotion and manipulation.
Then functional-specific algorithms such as footstep planning are applied to the low-dimensional space 
\arxiv{(see, e.g.,~\cite{CLCKHK05,KNKII01,PSBLY12,XCXZC09,KKNII02} for a partial list).}{(see, e.g.,~\cite{PSBLY12,XCXZC09} for a partial list).}
A high-dimensional planner is then used to ``track'' the plan generated in the low-dimensional space.


User guidance has been intensively incorporated in controlling the motion of humanoid robots, especially in complex tasks as those presented in the Darpa Robotics Challenge (DRC)~\cite{drc18}.
In such settings, guidance ranged from teleoperating the robot 
%through shared autonomy 
to high-level 
\arxiv{task guidance~\cite{mcgill2017team,zucker2015general,gray2017architecture,dedonato2017team,marion2017director}.}{{task guidance~(see e.g.,~\cite{mcgill2017team,gray2017architecture}).}}
However, as far as we are aware of, in all the aforementioned cases, \emph{identification} of when to use guidance was done by a human operator and not by the system (except for relatively simple metrics where the system asks for help when it fails to complete some given task).
Furthermore, the human guidance was used as a ``hard'' constraint forcing the system to make use of the guidance.
In contrast, in our work the system automatically and independently identifies when it is in need of guidance.
This guidance is then seamlessly incorporated as a soft constraint--- the system biases the search towards the guidance but also continues to explore the search space as if the guidance was not given.

 
\subsection{Multi Heuristic \astar (\mhastar)}
\label{sec:mha}
Multi Heuristic \astar (\mhastar)~\cite{NAL15,ASNHL16} is a search-based planning algorithm that takes in multiple, possibly inadmissible heuristic functions in addition to a single consistent heuristic termed the \emph{anchor} heuristic.
It then uses the heuristic functions to simultaneously perform a set of weighted-\astar~\cite{pohl1970first}-like searches.
Using multiple searches allows the algorithm to efficiently combine the guiding powers of the different heuristic functions. 

Specifically, for each search, \mhastar uses a separate priority queue associated with each heuristic. 
The algorithm iterates between the searches in a structured manner that ensures bounds on sub-optimality. 
This can be done in a round-robin fashion, or using more 
sophisticated approaches that allow to automatically calibrate the weight given to each heuristic~\cite{PNAL15}.

Part of the efficiency of \mhastar is due to the fact that the value of the cost-to-come (the $g$-value) computed for each state is shared between all the different searches\footnote{To be precise, there are two variants of \mhastar described in~\cite{ASNHL16}: Independent and Shared \mhastar where the queues do not share and do share the $g$-values of states, respectively. In this paper when we use the term \mhastar, it refers to the latter (shared) variant.}.
Sharing cost-to-come values between searches implies that if a better path to a state is discovered by any of the searches, the information is updated in all the
priority queues. 
Moreover, if one search ceases to make progress towards the goal (a state which we call ``stagnation region'' and which will be formally defined in Sec.~\ref{sec:planning}) it can use ``promising'' states found by other searches to escape this stagnation region.
%Furthermore, path sharing allows \mhastar to expand each state at most twice.
%Finally, in graph search, heuristic functions give a principled way to identify when the planner ceases to make progress (see, e.g.,~\cite{VNL17}).

\subsection{Identifying progress in search-based planners}

A key component in our work is automatically detecting when our planner requires user guidance.
This requires \emph{characterizing} regions where the planner ceases to make progress and algorithmic tools to \emph{detect} such regions. 
These two requirements are closely related to the notion of~\emph{heuristic depressions}~\cite{I92}
and~\emph{expansion delays}~\cite{DTR11,BRD13}.

A heuristic depression region is a  region in the search space where the correlation between the heuristic values and the actual cost-to-go is weak.
It is defined as a maximal connected component of states~$\mathcal{D}$ such that all states in the boundary of~$\mathcal{D}$ have a heuristic value that is greater than or equal to the heuristic value of any state in~$\mathcal{D}$.

Such regions often occur in real-time search algorithms such as \algname{LRTA*}~\cite{K90} and \algname{LSS-LRTA*}~\cite{KS09} where the heuristic function is updated as the search progresses.
Subsequently, current state-of-the-art algorithms  guide the search to avoide states that have been marked as part of a heuristic depression~\cite{HB12}.
As we will see, we will use a slightly different characterization of when the planner ceases to make progress which we call \emph{stagnation regions}. For details, see Sec.~\ref{sec:q1}. 


Expansion delay, defined as the average number of node expansions from when a node is generated until it is expanded, is a tool used to estimate the average progress that a planner makes along any single path.
When the heuristic used by a planner is perfect, the expansion delay equals one, while when performing uniform-cost search, the expansion delay can grow exponentially.
We will use the notion of expansion delays to identify when the planner is in a stagnation region (i.e., when it ceases to make progress towards the goal). For details, see Sec.~\ref{sec:q1}.



\section{Algorithmic approach---user-guided planning}
\label{sec:high}

\algrenewcommand\algorithmicindent{.8em}
\begin{algorithm}[tb]
\caption{User-guided planning ($\A$)}
\label{alg:main}	
\begin{algorithmic}[1]
\small
\While{$\neg\A.$\texttt{is\_solution\_found()} } 
	\While{$\neg\A.$\texttt{is\_in\_stagnation\_region()}} 
		\State $\A.$\texttt{run()}
		\Comment{no user guidance}
	\EndWhile
%	
	\State {$g \leftarrow$ \texttt{get\_user\_guidance()}}
	\Comment{$\A$ is in a stagnation region}
	\State $\A.$\texttt{update\_user\_guidance($g$)}
	\Comment{account for guidance}
	\While{$\A.$\texttt{is\_in\_stagnation\_region()}}
		\State $\A.$\texttt{run()}
		\Comment{$\A$ uses guidance to escape stagnation region}
	\EndWhile

	\State $\A.$\texttt{update\_user\_guidance($\neg g$)}
	\Comment {remove  guidance}
\EndWhile
\end{algorithmic}
\end{algorithm}

To employ our planning framework, we assume that we are given a motion-planning algorithm $\A$ that is endowed with two non-standard procedures which are planner dependent.
The first, \texttt{is\_in\_stagnation\_region()}, 
identifies when it is in a \emph{stagnation region}, namely when $\A$'s search does not progress towards the goal. 
The second, \texttt{update\_user\_guidance()}, 
incorporates (or removes) the user guidance provided to $\A$. 

Equipped with these functions, we can describe our planning framework, detailed in Alg.~\ref{alg:main}.
The framework runs as long as no solution is found (line~1).
It runs the planner~$\A$ (lines~2-3) as long as it continuously makes progress towards the goal (namely, it is not in a stagnation region).
Once a stagnation region is identified, user guidance is invoked (line~4) and $\A$  is updated to make use of this guidance (line~5).
It is then run while using the guidance as long as it is still in the stagnation region (lines~6-7).
Once it escapes the stagnation region, $\A$ is updated to remove the guidance that was provided by the user (line~8).


\section{User-guided planning via \mhastar}
\label{sec:planning}

We demonstrate our general planning framework described in Sec.~\ref{sec:high} for the case where the motion-planning algorithm~$\A$ is  \mhastar.
We assume that \mhastar has a set of possibly inadmissible heuristics in addition to the anchor heuristic. We will refer to these heuristics as \emph{baseline heuristics}.
The user guidance will be used to generate \emph{dynamic heuristics}.
We start (Sec.~\ref{sec:q1}-\ref{sec:q3}) by describing how we answer the three questions we posed in Sec.~\ref{sec:intro}.
We then continue (Sec.~\ref{sec:instantiation}) to detail how they are used in our planning framework.
%This implementation is slightly more complicated than that described in Alg.~\ref{alg:main} and is detailed in Sec.~\ref{sec:instantiation}.

\subsection{Invoking user guidance (Q1)}
\label{sec:q1}

\begin{figure}
  \centering
  \includegraphics[width=0.35\textwidth]{fig/local_min_detection_new2.pdf}
	\vspace{-3mm}

  \caption{%
    Visualization of the way vacillation-based stagnation regions are detected---expansion delay as a function of the number of expansions.  
    Notice that the stagnation regions ends when $e_{\text{curr}} = 1$ however, this is detected after $\omega$ additional steps.}
%    The expansion delay $e_{\text{curr}}$ and
%    the average expansion delay~$\Delta e(\omega)$, 
%	computed over some recent history~$\omega$ 
%	are depicted using solid blue and dashed red lines, respectively.
%	The stagnation region is depicted using the gray region. 
%	It is detected once $\Delta w(\omega) \geq \tau$, where $\tau$ is some predefined threshold.
% 	The stagnation regions ends when $e_{\text{curr}} = 1$ however, this is detected after $\omega$ additional steps.}%

	\vspace{-3mm}
  \label{fig:filmstrip-local-min}%
\end{figure}




\begin{figure*}[t]%
%\captionsetup{format = plain}
  \centering%
  \subfigure[]
  {
  \includegraphics[width=0.314\textwidth]{fig/local_min_detection_1.pdf}
  \label{fig:local_min1}
  }
  \hspace{-5mm}
%  \subfigure[]
%  {
%  \label{fig:local_min2}
%  \includegraphics[width=0.265\textwidth]{fig/local_min_detection_2.pdf}
%  }
%  \hspace{5mm}
  \subfigure[]
  {
  \label{fig:local_min3}
  \includegraphics[width=0.314\textwidth]{fig/local_min_detection_3.pdf}
  }  
  \hspace{-5mm}
  \subfigure[]
  {
  \label{fig:local_min4}
  \includegraphics[width=0.314\textwidth]{fig/local_min_detection_4.pdf}
  }
  \vspace{-2mm}
  \caption{%
    Visualization of heuristic-based stagnation-region detected.   
	\subref{fig:local_min1}~Heuristic $h(s_i)$ (solid blue) has three local minima, $m_1, m_2$ and $m_3$ followed by three stagnation regions (light grey). Local minima $m_2$ is very small while~$m_3$ is not a local minimum per se, yet the progress made between consecutive steps is smaller than the predefined threshold~$\varepsilon$.
    %
    \subref{fig:local_min3}~The function $\kappa(i,\omega_1)$ (dashed green) returns the minimal value $h(s_i)$ attained over the past~$\omega_1$ iterations (referred to  as the ``recent history'').
    %
%    \subref{fig:local_min3}~
    The function $\kappa(i-\omega_2,\omega_1-\omega_2)$ (dotted red) returns the minimal value $h(s_i)$ attained over the beginning of the recent history.
    %
    \subref{fig:local_min4}~The difference between the two functions (solid purple) indicates if there was significant progress (i.e., more than $\varepsilon$) made at the end of the recent history when compared to the beginning of the recent history. 
    If not, then the planner detects a stagnation region (dark grey).
		Notice that the hysteresis parameters~$\omega_1$ and~$\omega_2$ 
		(i)~induce a lag from the time that the stagnation region starts until it is detected,
		(ii)~allow to avoid detecting stagnation region~$r_2$.  
		}%

  \label{fig:filmstrip-local-min2}%

  \vspace{-2.5mm}

\end{figure*}

The heuristic functions of search-based planning algorithms, such as \mhastar, can be used to estimate in a principled manner when the planner is in a stagnation region (Alg~\ref{alg:main}, lines 2 and~6). 
%
We suggest two alternative methods to identify when the planner ceases to make progress towards the goal, each resulting in a slightly different definition of a  stagnation region.
The first, which we call \emph{vacillation-based detection} using the notion of expansion delays~\cite{DTR11}:
Let~$\Q$ be a priority queue and let $e_\text{curr}$ be a counter tracking the total number of node expansions performed when using~$\Q$.
When a node is expanded, for each child node $s$ we store the current expansion number using a counter $e(s)$.
Now, the expansion delay for a state $s$ is defined as
$$
\Delta e = e_\text{curr} - e(s).
$$ 



Given some parameter $\omega >0$ we compute $\Delta e(\omega)$, the average expansion delay over a moving window of size $\omega$. 
%This gives a principled way to identify when a planner ceases to make progress towards the goal, a state which we call \emph{stagnation}:
\begin{definition}
\label{def:expansion_delay}
Let 
$\omega>0$ be some window size
and
$\tau$ be some threshold value.
A heuristic~$h$ associated with a queue~$\Q$ is defined to
\begin{enumerate}
	\item enter a stagnation region if $\Delta e(\omega) \geq \tau$,
	\item exit a stagnation region if $\Delta e(\omega) = 1$
\end{enumerate}
\end{definition}
For a visualization of vacillation-based stagnation regions and how they are detected (Def.~\ref{def:expansion_delay}), see Fig.~\ref{fig:filmstrip-local-min}.

As we will see in our experimental section, using expansion delays to measure progress may cause the planner to falsely detect that it makes progress when it clearly does not.
Thus, we suggest an alternative method, which we call \emph{heuristic-based}, to detect when the planner ceases to progress towards the goal.
Let~$\Q$ be a priority queue 
ordered according to some heuristic function~$h(\cdot)$,
$s_i$ be the node expanded from~$\Q$ at the $i$'th iteration and $\omega_1, \omega_2$ be parameters such that $\omega_1 > \omega_2$.
%
We define 
$\kappa_\Q(i, \omega) = \min_{i-\omega \leq j \leq i} \{ h(s_j)\}$.
Namely, $\kappa_\Q(i, \omega)$ denotes the minimal value attained by $h$ in the past~$\omega$ states. 
%
\begin{definition}
\label{def:heur}
A heuristic~$h$ associated with a queue~$\Q$ is defined to be in a (heuristic-based) stagnation region if 
$\kappa_\Q(i, \omega_1) \geq \kappa_\Q(i - \omega_2, \omega_1 - \omega_2) - \varepsilon$.
\end{definition}
\noindent Namely,~$\Q$ is in a heuristic-based stagnation region if looking at the previous~$\omega_1$ iterations, 
there was no reduction 
(by more than some threshold $\varepsilon$) 
in the minimum value of~$h$ 
in the last~$\omega_2$ states expanded from $\Q$.
%
%
%Thus, our algorithm is given three additional parameters~$\omega_1, \omega_2$ and $\varepsilon$ 
%and maintains  for each queue~$\Q$ the values~$\kappa_\Q(i, \omega_1)$ and $\kappa_\Q(i - \omega_2, \omega_1 - \omega_2)$.
For a visualization of heuristic-based stagnation regions and how they are detected (Def.~\ref{def:heur}), see Fig.~\ref{fig:filmstrip-local-min2}.



%\os{
%Note that testing if a single queue is in a stagnation region takes $O(1)$ time.
%For a visualization, see Fig.~\ref{fig:filmstrip-local-min}.
%}


%The heuristic functions of search-based planning algorithms, such as \mhastar, can be used to estimate in a principled manner when the planner is in a stagnation region (Alg~\ref{alg:main}, lines 2, 6). 
%%Specifically, in such algorithms,  we proceed by iteratively choosing  the current-best state from a priority queue and computing all its successors. 
%%
%We suggest to identify when the planner is in a stagnation region as follows:
%Let~$\Q$ be a priority queue 
%ordered according to some heuristic function~$h(\cdot)$,
%$s_i$ be the node expanded from~$\Q$ at the $i$'th iteration and $\omega_1, \omega_2$ be parameters such that $\omega_1 > \omega_2$.
%%
%We define 
%$\kappa_\Q(i, \omega) = \min_{i-\omega \leq j \leq i} \{ h(s_j)\}$.
%Namely, $\kappa_\Q(i, \omega)$ denotes the minimal value attained by $h$ in the past~$\omega$ states. 
%%
%\begin{definition}
%A heuristic~$h$ associated with a queue~$\Q$ is defined to be in a stagnation region if 
%$\kappa_\Q(i, \omega_1) \geq \kappa_\Q(i - \omega_2, \omega_1 - \omega_2) - \varepsilon$.
%\end{definition}
%\noindent Namely,~$\Q$ is in a stagnation region if looking at the previous~$\omega_1$ iterations, 
%there was no reduction 
%(by more than some threshold $\varepsilon$) 
%in the minimum value of~$h$ 
%in the last $\omega_2$ states expanded from $\Q$.
%
%
%Thus, our algorithm is given three additional parameters~$\omega_1, \omega_2$ and $\varepsilon$ 
%and maintains  for each queue~$\Q$ the values~$\kappa_\Q(i, \omega_1)$ and $\kappa_\Q(i - \omega_2, \omega_1 - \omega_2)$.
%Note that testing if a single queue is in a stagnation region takes $O(1)$ time.
%For a visualization, see Fig.~\ref{fig:filmstrip-local-min}.


\subsection{Form of user guidance (Q2)}
\label{sec:q2}
We chose to obtain user guidance 
(Alg~\ref{alg:main}, line~4)
in the form of an intermediate configuration $\hat{q}$ that is used to guide the planner. 
%
The framework includes a graphical user interface (GUI) (Fig.~\ref{fig:gui}) capable of  depicting the robot and the workspace.
Once user guidance is invoked, 
a configuration in the stagnation region is obtained and the robot is placed in that configuration (as well as the start configuration and target region) in the GUI.
This allows the user to intuitively try and understand where the planner faces difficulty and how to guide it out of the stagnation region.
The user then suggests the guidance $\hat{q}$ by moving the robot's joints and end effectors.
The tool runs a state validity checker in the background which restricts the user from providing invalid configurations, e.g. with respect to collision, joint limits and stability.
%Note that the user is \emph{not} required to be familiar with the search algorithm.

\begin{figure}[tb]
  \centering
  	\includegraphics[width=0.355\textwidth]{fig/panel.png}
  	%\vspace{-2mm}
  \caption{
		GUI used to provide guidance to the planner. The panel on the right hand side allows to select different joint groups, move the joints and pass the guidance to the planner. The interactive marker shown on the left hand side allows to move the robot's end effectors.
}
   	\label{fig:gui}
  	\vspace{-4.5mm}
\end{figure}

\subsection{Using user guidance (Q3)}
\label{sec:q3}

\begin{figure*}[t]%
%\captionsetup{format = plain}
  \centering%
  \subfigure[]
  {
  \includegraphics[width=0.182\textwidth]{fig/example_1.pdf}
  \label{fig:dynamic_heuristic1}
  }
  \subfigure[]
  {
  \label{fig:dynamic_heuristic2}
  \includegraphics[width=0.182\textwidth]{fig/example_2.pdf}
  }
  \subfigure[]
  {
  \label{fig:dynamic_heuristic3}
  \includegraphics[width=0.182\textwidth]{fig/example_3.pdf}
  }  
  \subfigure[]
  {
  \label{fig:dynamic_heuristic4}
  \includegraphics[width=0.182\textwidth]{fig/example_4.pdf}
  }
	\vspace{-3mm}
  \caption{%
    Algorithm progression.
    States popped from a priority queue~$Q$ (still in~~$Q$) are depicted using dark (light) colors.
    Start, target and user-guided states are depicted in purple with the letters \texttt{s}, \texttt{t}, \texttt{g}, respectively. 
    %
    In this example \mhastar alternates between queues in a round-robin fashion and heuristic values are inflated by a weight of $w=\infty$. 
    %Namely, the priority queues are ordered according to the heuristic-value of the states.
    %
	\subref{fig:dynamic_heuristic1}~\mhastar starts with a single baseline heuristic (green) which is the Euclidean distance to goal and a stagnation region is identified.
    %
	\subref{fig:dynamic_heuristic2}~User provides guidance~$\texttt{g}$ and an additional heuristic (red) is automatically generated and drives the search towards the guidance (notice that the anchor heuristic continues to search the local minimum).
    %
	\subref{fig:dynamic_heuristic3}~After passing through the~$\texttt{g}$, the additional heuristic (red) drives the search towards the goal.
    %
	\subref{fig:dynamic_heuristic4}~After the additional heuristic found states that are placed at the top of~$Q$, the additional heuristic is deleted and the anchor heuristic continues to drive the search towards the goal.
  }%
  \label{fig:filmstrip-dynamic_heuristic}%
  \vspace{-2.5mm}
\end{figure*}



We assume that \mhastar has at least one baseline heuristic~$h_{\text{goal}}$ which approximates the cost to reach the goal from every state.
Furthermore, we assume that for every configuration~$q$, there exists a (possibly inadmissible) heuristic $h_q$ where~$h_q(s)$ estimates the cost to reach $q$ from state $s$.
%
%we assume that there exists a family of (possibly inadmissible) heuristic functions $\H$, such that for every configuration~$q$, there exists a heuristic $h_q \in \H$ where~$h_q(s)$ estimates the cost to reach $q$ from state $s$.
%%%%

Given user guidance in the form of a configuration $\hat{q}$, we dynamically generate a new heuristic $$
    \hat{h}(s)= 
\begin{cases}
    h_{\hat{q}}(s) + h_{\text{goal}}(\hat{q}),	& 
    		\text{if } \hat{q} \text{ is not an ancestor of } s,\\
    h_{{goal}}(s),            		& 
    		\text{if } \hat{q} \text{ is an ancestor of } s.
\end{cases}
$$
Namely,~$\hat{h}$ estimates the 
cost to reach the goal  by passing through $\hat{q}$ (see also~\cite{CGD86} for intuition regarding such a heuristic). 
If the state was reached by passing through~$\hat{q}$, then the value of $\hat{h}$ is simply the estimation of the cost to reach the goal.


Equipped with the heuristic $\hat{h}$, we add a new queue to \mhastar prioritized using the~$\hat{h}$. %(Alg~\ref{alg:main}, line~4). 
States expanded using this queue will be biased towards $\hat{q}$ (see also~\cite{INL15} for more details on adding heuristics and queues dynamically to \mhastar
%and~\cite{NAL15} for more details on dealing with calibrating the different values used by different heuristic functions
).
Recall that in \mhastar, nodes are shared between the different queues.
Thus, once a state has been found that can be used to get the planner out of the stagnation region, it will be expanded by the other queues using their heuristics.
Once this is detected 
%(Alg~\ref{alg:main}, line~8),
the newly-added queue is removed.

In general,  we can add a dynamic queue for every baseline heuristic if there are more than one. However, for simplicity, in this work we use a single baseline heuristic and add one dynamically generated queue when the user provides guidance.

\subsection{User-guided \mhastar}
\label{sec:instantiation}
We are now ready to describe how we apply our general framework (Alg.~\ref{alg:main}) to the case of \mhastar.
This differs slightly from the approach described in Sec.~\ref{sec:high} due to our ability to identify which queue is in stagnation and to detect if the configuration~$\hat{q}$ (i.e., the guidance) was reached.

Specifically, if the baseline heuristic escaped a stagnation region but the configuration $\hat{q}$ was \emph{not} reached, we suspend the dynamic queue but do not discard it. 
This is done to first try reusing the last guidance before obtaining a new one. 
Thus, when the planner will detect that it is in a stagnation region, it will first resume the suspended dynamic heuristic (if one exists).
%
If the baseline heuristic escaped a stagnation region and the configuration~$\hat{q}$ was  reached it will no longer be useful again and hence will be discarded.
Finally, if the dynamic heuristic is in a stagnation region then it is discarded and the user will be queried for a new guidance. 

For pseudo-code describing each specific function used  in Alg.~\ref{alg:main}, see Alg.~\ref{alg:instantiation}.
For a visualization of the way the algorithm progresses, see Fig.~\ref{fig:filmstrip-dynamic_heuristic}. Note that although for the illustrated example, the search happens to pass through the guidance, in general it is not a constraint in the framework. 
%
%Specifically, the planner can be in a local minima in the dynamically-generated queue that is used to escape the original local minima. 
%In such cases we request new guidance from the user and replace the previous guidance with the new one.

%\algrenewcommand\algorithmicindent{2em}
\begin{algorithm}[tb]
\caption{User-guided \mhastar}
\label{alg:instantiation}	
\begin{algorithmic}[1]
\small
%\State \textbf{function} \texttt{is\_in\_stagnation\_region()}
\Function{\texttt{is\_in\_stagnation\_region()}}{}
 	\If {baseline heuristic not in stagnation}
		\State \textbf{return} true
	\Else
		\State \textbf{return} false
	\EndIf
\EndFunction
%	
\vspace{2mm}
%
\Function{\texttt{get\_user\_guidance()}}{}
%
	\If {exists suspended dynamic heuristic}
		\State \textbf{return}  {suspended dynamic heuristic}
	\Else
		\State{get new user guidance and add dynamic heuristic}
		\State \textbf{return}	{new dynamic heuristic}
	\EndIf
\EndFunction 
%	
\vspace{2mm}
%
\Function{\texttt{remove\_user\_guidance()}}{}
	\If {dynamic heuristic is in stagnation}
		\State {remove dynamic heuristic}
		\Comment{guidance is not useful}
	\Else 	\Comment{dynamic heuristic is not in stagnation}
		\If {states passed through guidance}
			\State {discard dynamic heuristic}
			\Comment{will not be useful in future}
		\Else
			\State {suspend dynamic heuristic}
			\Comment{may be useful in future}
		\EndIf
	\EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Evaluation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation }
\label{sec:eval}
We evaluated the performance of our planning framework on a 34-DOF WAREC humanoid robot~\cite{MHSetal15} 
which is constrained to maintain static stability at all times. 
% The robot has four symmetric limbs each having seven revolute joints. The other six dimensions come from the pose of the robot with respect to some global frame of reference. 
%
%\subsection{Implementation details}
To construct the search space, we used a set of motion primitives which are short kinematically feasible motion sequences. 
These are used to generate the actions, or the successors, of a state during the search. 
For additional details see~\cite{DL18}
%These primitives generate motions for the limbs and torso of the robot (\todo{cite Andrew's paper}). 

% These primitives included clockwise and counter-clockwise rotation of individual joints. 
% Specifically, four different types of motion primitives are used:
% (i)~primitives for the free limbs of the robot i.e. the limbs whose end effectors are not constrained by any contact surface,  
% (ii)~primitives to move the torso of the robot,
% (iii)~primitives to latch onto the target end-effector poses
% and
% (iv)~primitives to latch onto the user-provided configuration once it is within a small threshold distance to the state being expanded.
% Notice that motion primitives (ii) and (iii) require solving closed-chain inverse kinematics for the constrained limbs.

For each experiment we used a small set of fairly generic heuristics. 
This was done to demonstrate that our approach allows to significantly reduce the engineering effort required in carefully crafting domain-specific heuristics. 
We conducted two experiments which largely differ in the nature of mobility and thus employ different baseline heuristic functions. 
However, the dynamic heuristic function in both the experiments is the Euclidean distance in the joint 34-DOF space.
The parameter values used in both experiments are $\omega_1 (200), \omega_2 (50)$ and $\varepsilon (50)$ for the heuristic-based, and $\tau (30)$ and $\omega (10)$ for the vacillation-based stagnation region detection.
We conducted the same experiments (results ommited due to lack of space) with a wide variety of parameters and obtained  only slight differences in the results demonstrating that our approach is highly robust to the choice of parameters for our domain.

Planning statistics for all experiments are provided in Table~\ref{tab:stats}.
Notice that in all the experiments the planner succeeds to reach the goal with the help of a user. 
The deviations in the results come from the quality of the guidance provided.
For videos demonstrating the approach, 
%see~\url{https://goo.gl/cjJ7KU}.
see~\url{https://drive.google.com/drive/folders/1OFJ7XwbiVVbgw1vmentz575nTCrQBtCu?usp=sharing}.

%see~\url{https://drive.google.com/open?id=137rTFQdE7VW9zluy6EV5GVcLzyP0XDlQ}.
\begin{table}
 \resizebox{\linewidth}{!}{%
  \begin{tabular}{lcccc}
    \hline
    \multirow{2}{*}{} &
      \multicolumn{2}{c}{Bipedal locomotion} &
      \multicolumn{2}{c}{Ladder mounting} \\
      & (a) & (b) & (a) & (b) \\
      \hline
    Planning time(s)  & 205.2   $\pm$    22.7  & 183.4   $\pm$  25.0          & 149.4 $\pm$ 30.0   & 101.4 $\pm$ 10.3  \\
    Total time(s)     & 293.5   $\pm$    33.1  & 256.9   $\pm$  38.0          & 176.3 $\pm$ 29.6   & 128.4 $\pm$ 10.3 \\
    Expansions        & 1800.1  $\pm$    88.3  & 1770.5  $\pm$  125.9         & 980.8 $\pm$ 240.6  & 644   $\pm$ 69.3 \\
    Num. of guidances & 5.4     $\pm$    1.17  & 5.4     $\pm$  1.1           & 4.7   $\pm$ 1.2    & 5     $\pm$ 0.8   \\
    Guidance time     & 16.4    $\pm$    2.8   & 13.6    $\pm$  3.6           & 6.0   $\pm$ 1.5    & 5.5   $\pm$ 0.9  \\
    \hline
  \end{tabular}} 	
  \caption{Experimental results for the bipedal locomotion and ladder mounting tasks for (a) vacillation-based detection (b) heuristic-based detection averaged over 10 trials.}
  \label{tab:stats}
	\vspace{-4mm}
\end{table}
\begin{figure*}[t]%
%\captionsetup{format = plain}
  \centering%
  \subfigure[]
  {
  \includegraphics[width=0.2125\textwidth]{fig/bar_2.png}
  \label{fig:stuck_bar}
  }
  \subfigure[]
  {
  \label{fig:stuck_tables}
  \includegraphics[width=0.2125\textwidth]{fig/tables_1.png}
  }
  \subfigure[]
  {
  \label{fig:stuck_door}
  \includegraphics[width=0.2125\textwidth]{fig/door_2.png}
  }  
  \subfigure[]
  {
  \label{fig:stuck_step}
  \includegraphics[width=0.2125\textwidth]{fig/step_2.png}
  }
  \caption{%
    Bipedal locomotion in challenging scenarios: 
  \subref{fig:stuck_bar}~The robot has to squat or bend down to pass under a beam.
    %
  \subref{fig:stuck_tables}~The robot has to pass through two tables by may be lifting the elbows high above the tables.
    %
  \subref{fig:stuck_door}~The robot has to squeeze through a narrow doorway by tucking in its arms.
    %
  \subref{fig:stuck_step}~The robot has to step onto a relatively high platform to reach the goal for which it has to lean a little bit more to its left side to be able to lift the left foot further up.
  }%
  \label{fig:biped_locomotion}%
  \vspace{-4.5mm}
\end{figure*}

\begin{figure}[t]%
%\captionsetup{format = plain}
  \centering%
  \subfigure[Vacillation-based detection]
  {
  \includegraphics[height=3.75cm]{fig/ed_plot.pdf}
%  \includegraphics[width=0.346\textwidth]{fig/ed_plot.pdf}
  \label{fig:ed_plot}
  % \includegraphics[width=0.3\textwidth]{fig/ladder.png}
  }  
%
	\vspace{-3mm}
  \subfigure[Heuristic-based  detection]
  {
  \includegraphics[height=3.75cm]{fig/h_plot.pdf}  
%  \includegraphics[width=0.346\textwidth]{fig/h_plot.pdf}
  \label{fig:h_plot}
  % \includegraphics[width=0.3\textwidth]{fig/staircase.png}
  }
%
  \caption{%
    \mhastar progress with and without guidance.
    \subref{fig:ed_plot}~vacillation-based 
    and
    \subref{fig:h_plot}~heuristic-based
    stagnation-region detection.
    %---heuristic values as a function of the number of queue expansions.
%		When a stagnation region is detected (red cross) in the baseline heuristic (cyan), a dynamic heuristic is generated (blue) until the stagnation region is escaped (green circle) or until a new stagnation region is detected (blue cross) in the dynamic heuristic.
%		Plots depicting the baseline heuristic values when only a limited amount of guidance is given demonstrate that without guidance, the planner remains stuck in the stagnation region (we note that as \mhastar is complete, it will eventually escape all such regions).
		}

  \label{fig:detection_plot}%

  \vspace{-4.5mm}

\end{figure}

\subsection{Bipedal locomotion}
\label{subsec:locomotion}



%The first task we considered is bipedal locomotion. The initial state of the robot is the full dimensional 34-DOF configuration whereas the goal is represented as a cylindrical region which the robot needs to enter (depicted in Fig.~\ref{fig:robot}).

The first task we considered is bipedal locomotion, depicted in Fig.~\ref{fig:robot}.
Here, we employ the recently-introduced adaptive dimensionality 
\arxiv{framework~\cite{GCBSL11,GSL12,GSL13}}{framework~\cite{GCBSL11}}
which consists of two stages: an adaptive-planning phase which plans in a low-dimensional space when possible and a tracking phase which plans in the high-dimensional space.
Our user-guided planner is integrated within the high-dimensional planner by searching for a path that tracks the footstep plan generated in the adaptive-planning  phase. 

The baseline heuristic we used was designed to assist the search with a general walking or stepping capability. For each step the footprint of the target footstep is visualized for the user to be able to better understand where the planner is stuck and how to provide the guidance. In relatively easier scenarios this heuristic would suffice in guiding the search. However if the search encounters harder situations such as those depicted in Fig.~\ref{fig:biped_locomotion}, then it is likely to get trapped into a stagnation region and would invoke user-guidance.

Results demonstrating the effectiveness of our framework are depicted in Fig.~\ref{fig:detection_plot}.
Specifically, we plot the 
method to detect stagnation regions (expansion delay and heuristic values for vacillation-based and heuristic-based detection, respectively) as a function of the number of queue expansions.
For both methods, we ran our algorithm with and without user guidance.
Namely, if a stagnation region was detected, we recorded the state of the planner and then continued to run it once without asking the user for guidance and once using our approach. This was done every time a stagnation region was detected. 
Results show that without guidance, the planner is not able to make any significant progress and the heuristic value does not change.
On the other hand, when guidance is given, then the algorithm escapes the stagnation region and resumes to make progress towards the goal.

Interestingly, using expansion delays to detect a stagnation region (vacillation-based detection) incurs a lot of noise---notice the large oscillations in the dashed yellow curve in Fig.~\ref{fig:ed_plot}. 
A possible explanation is that even in regions where the planner cannot ultimately progress towards the goal, there may be multiple short feasible paths to explore. In such settings, then the expansion delay for each such path will can small while the planner does not really progress towards the goal.
Indeed, numerical results stated in Table~\ref{tab:stats} confirm that our heuristic-based method for stagnation-region detection outperforms the existing  vacillation-based method.
We observed similar trends for the second experiment (ladder climbing) that caused falsely detecting that a stagnation region was exited, plots omitted.


\subsection{Mounting onto a ladder}
The second task we considered was mounting onto a ladder from a standing position (see Fig.~\ref{fig:gui}) to the desired contact poses. This problem is challenging because the ladder rungs and the robot grasping hooks construct narrow spaces in the configuration space which have to be traversed to establish the desired contacts. The baseline heuristic  used is the summation of four six-dimensional Euclidean distances between each of the four end effectors and their respective target poses. 
For numerical results, see Table~\ref{tab:stats}.

% \subsection{Climbing a staircase}
% \label{subsec:stairs}
% The second task we considered is climbing up a set of stairs while avoiding collision with obstacles (steps and handrails) as well as adhering to the physical constraints of the robot (see Fig.~\ref{fig:robot}). The initial state of the robot again is the full dimensional 34-DOF configuration of the robot but the goal state in this experiment is represented just as a cylindrical region which the robot needs to enter (depicted in Fig.~\ref{fig:stair_plot}).

% In the absence of handrails the planner successfully finds a path to the goal without invoking the user for guidance. The handrails make the planning problem  harder. As the robot has to sway sideways during the stepping motion to maintain static stability, the handrails constrain its mobility.
% To this end, we allow the user to provide guidance to the planner using the notion of support surfaces. 
% We prespecify a set of valid contact surfaces (handrail cylinders in this experiment). When the user brings any of the robot hands within a threshold distance to a valid contact pose on a support surface, the GUI snaps the robot state to establish a valid support contact by solving the inverse kinematics for the respective limb. The planner incorporates this contact information while doing the stability evaluation for a state. 


% Resultantly, when the user provides guidance, the dynamic heuristic guides the search to reach this user-provided state and continues to expand its successor states which moves the robot forward while maintaining the hand contact.
 
% In the context of motion primitives, here we allow two types of motions for the robot torso, one with the hands in contact and the other that allow free motions for the robot arms. This helps the robot to let go of the handrail when it no longer needs the support. A single baseline heuristic is used in this experiment which assists the search with a general walking or stepping capability for the robot.
% However, it is not designed to avoid obstacles or utilize support surfaces.



% We conducted a similar experiment to the one described in Sec.~\ref{subsec:stairs} where we simulate the progress with and without user guidance for each depression region detected.
% A similar trend can be seen in Fig.~\ref{fig:h_plot}. Note that for this experiment the plot depicts the instances where the dynamic heuristic also gets stuck in stagnation region because of the imperfections in the guidance but then eventually escapes it with additional guidances.


%% stats
%We evaluated the performance by running the experiments on the two environments. The results are shown in table~\ref{tab:stats}. In all the experiments the planner succeeds to reach the goal with the help of a user. The deviations in the experiments come from how good or bad the guidances were.


%\removed{
%\subsection{Robustness to algorithmic parameters}
%We introduced three parameters in section Sec.~\ref{sec:q1} i.e ~$\omega_1, \omega_2$ and $\varepsilon$ which govern where the user guidance will be invoked. We can show that our approach is not very sensitive to the change in these parameters and thus they don't require fine tuning. The results presented in Fig. ~\ref{fig:h_plot} are for some nominal values of the parameters. 
%}

%\removed{
%For the experiments that we conducted, the results don't vary with changing $\omega_1$ because the heuristic functions that we used don't show dips as illustrated in the hypothetical illustration in Fig.~\ref{fig:filmstrip-local-min} but in general, such a trend can occur in an arbitrarily inadmissible heuristic. $\varepsilon$ is a domain dependent parameter and its magnitude should be set relative to the scale of the corresponding heuristic function. For instance if we use $n$ baseline heuristics, then the value of $\varepsilon$ for each of these heuristics should be proportional to the scale of that heuristic. Having said that one can fix $\varepsilon$ and tune the parameter $\omega_2$ until you get the desired behaviour, as both of them are correlated and measure the rate of progress being made by a heuristic. }
%
%\removed{
%To show robustness to $\omega_2$, we linearly swept its value over a window centred at the nominal value used for experiments and checked how many of the stagnation region detections matched with the nominal results. Fig. ~\ref{fig:robustness} shows the evaluation for the two experiments. For the values of $\omega_2$ where the matching ratio is 1, the planner would have invoked the user exactly for the same stagnation regions as the ones for which the guidance was called using the nominal parameters.}

%\begin{figure}[t]%
%%\captionsetup{format = plain}
%  \centering%
%  \hspace{-2mm}
%  \subfigure[\footnotesize Mounting onto the ladder]
%  {
%  \includegraphics[width=0.20\textwidth]{fig/ladderly.png}
%  
%  \label{fig:robust_ladder}
%  }
%%
%  \subfigure[\footnotesize Climbing up the staircase]
%  {
%  \includegraphics[width=0.20\textwidth]{fig/stairly.png}
%  \label{fig:robust_stair}
%  }
%
%  \caption{%
%\removed{    The plot shows the ratio of the number stagnation region detections matched to the total number of regions detected by the nominal parameter values, for $\omega_2$ values swept around the nominal value (50) by $\pm$ 40 expansions with a step of 5. }
%  \vspace{-5mm}
%}
%   	\label{fig:robustness}
%\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Discussion and future work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Discussion and future work}
\section{Discussion}
\label{sec:future}

%\subsection{Discussion}
In Sec.~\ref{sec:eval} we demonstrated how user guidance allows to solve highly-constrained motion-planning problems in high-dimensional spaces with only simple baseline heuristics.
An alternative approach would be to add domain-dependent carefully-crafted heuristics~\cite{V17} which allow to faster solve the same problems completely autonomously.

When faced with a new problem domian 
(say, climbing a ladder, crawling on uneven terrain etc.)
we can either design additional heuristics to tackle this problem or shift the burden to the user to provide online  guidance.
If our problem requires planning in multiple, diverse domains this problem is accentuated---should we  use a large arsenal of heuristics that can address each domain or should we have a small set of baseline heuristics that will (roughly) address all domains and rely on user guidance when these baseline heuristics fail?
There is no clear answer to this question and our approach simply offers a general alternative to existing approaches.


%\subsection{Future work}
%%While providing promising initial results, our framework is far from being complete.
%We are interested in experimenting with alternative forms of user guidance such as providing a \emph{constrained sub-manifold} of the configuration space which can be more informative for the planner instead of providing it with a single joint configuration and could potentially reduce the number of user invocations. 
%Finally, once a guide is given, we want our planner to be able to \emph{generalize} the guidance obtained to future stagnation regions that are similar in nature to the ones encountered (e.g., climbing up multiple stairs).
%
%\removed{Finally we are interested in implemented our approach using sampling-based planners. Here, once the user will provide guidance, it can be used to bias the sampling procedure. 
%An open challenge remains how to automatically detect that the planner is not progressing toward the goal.}


\newpage

%\bibliographystyle{plainnat}
\bibliographystyle{named}
%\bibliographystyle{abbrv}
\bibliography{bibliography}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai18.sty is the style file for IJCAI-18 (same as ijcai08.sty).
\usepackage{ijcai18}

% Use the postscript times font!
\usepackage{times}
\usepackage{xcolor}
\usepackage{soul}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}

\usepackage{savesym}
\usepackage{amsmath,amssymb,amsfonts}
%\usepackage[numbers]{natbib}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm,algorithmicx}
\usepackage{comment}
\usepackage{xspace}
\usepackage{scalerel}
\usepackage{xcolor}
%\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage[left]{showlabels}
\usepackage{multicol}
\usepackage[bookmarks=true]{hyperref}
\usepackage{graphicx,subfigure}

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{	Online, interactive user guidance for \\
		high-dimensional, constrained motion planning }

\author{Fahad Islam$^{\dag}$, Oren Salzman$^{\dag}$ and Maxim Likhachev$^{\dag}$% <-this % stops a space
  \thanks{$^{\dag}$Robotics Institute, Carnegie Mellon University,
    Pittsburgh, USA
    {\tt\small \{fi,osalzman\} at andrew.cmu.edu, maxim@cs.cmu.edu}
  }%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\input{macros.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
We consider the problem of planning a collision-free path for a high-dimensional robot.
Specifically, we suggest a planning framework where a motion-planning algorithm can obtain guidance from a user.
In contrast to existing approaches, we suggest to seek user guidance only when the planner identifies that it ceases to make significant progress towards the goal.
User guidance is given in the form of an intermediate configuration~$\hat{q}$ which, in turn, is used to bias the planner to go through $\hat{q}$.
We demonstrate our approach for the case where the planning algorithm is Multi-Heuristic A* (MHA*) and the robot is a 34-DOF humanoid.
We show that using this general approach allows to compute highly-constrained paths such as climbing stairs with little domain knowledge.
Without our approach, solving such problems require carefully-crafted domain-dependent  heuristics. 
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Intro
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{comment}

\section{Introduction}
\label{sec:intro}

Motion-planning is a fundamental problem in robotics that has been studied for over four decades~\cite{CBHKKLT05,L06,S04}.
However, efficiently planning paths in high-dimensional, constrained spaces remains an ongoing challenge.
One approach to address this challenge is to incorporate user input to guide the motion-planning algorithm.
While there has been much work on planning using human demonstration 
(see, e.g.,~\cite{ACVB09,HS16,PHCL16,SHLA16,YA17}), 
there has been far less research incorporating guidance as an interactive part of the planning~loop.

Broadly speaking, interactive planning has been typically used in the context of sampling-based motion-planning algorithms~\cite{L06}.
User guidance was employed by biasing the sampling scheme of the planner.
This was done by having the user mark regions in the \emph{workspace} that should be avoided or 
%explored~\cite{DSJA14}.
explored~\cite{DSJA14,MTMKDC15,YPB15}.
%\os{Mention Vinitha's paper when arXived}
Alternatively, interactive devices such as a 3D mouse or a haptic arm have been used to generate paths in a (low-dimensional) configuration space. This path was then used by a planner to bias its 
%sampling domain~\cite{TFF12}.
sampling domain~\cite{BTFF16,FTF09,TFF12}.
%Interestingly, in all the examples mentioned, an implicit assumption taken is that the user is dedicated to guide and interact with the planning algorithm.

We are interested in planning in high-dimensional, constrained spaces such as those encountered by a humanoid robot (see Fig.~\ref{fig:robot} and Sec.~\ref{sec:rel}).
In such settings, workspace regions often give little guidance to the planner due to the high dimension of the configuration space as well as the physical constraints of the robot.
Additionally, obtaining user guidance in the configuration space is extremely time consuming, even for expert users.
Thus,  while beneficial, user guidance should be employed scarcely.

Our key insight is that carefully chosen individual configurations suggested by a user can be used to effectively guide the planner when in need.
Transforming this insight into a planning framework requires addressing three fundamental questions:

\begin{itemize}
	\item[\textbf{Q1.}] When should the planner ask the user for guidance?
	\item[\textbf{Q2.}] What form should the user's guidance take?
	\item[\textbf{Q3.}] How should the guidance be used by the planner?
\end{itemize}

Identifying \emph{when} to obtain guidance 
(Q1, Sec~\ref{sec:q1}) 
comes in stark contrast to existing approaches---we suggest to only employ user guidance when the planner \emph{identifies} that it ceases to make significant progress towards the goal.
The specific type of guidance given 
(Q2, Sec~\ref{sec:q2}),
as previously mentioned,
is configuration-space based and \emph{not} workspace-based. This deviation from previous work is due to our specific setting of high-dimensional, constrained systems.
Finally, guidance is used to \emph{bias} the search algorithm towards regions that are likely to be beneficial (Q3, Sec~\ref{sec:q2}). 
It is worth emphasising that this is done without requiring the user to understand the underlying search algorithm. 

% 
%In the following, we detail our planning framework (Sec.~\ref{sec:high}) and how it addresses each of these questions (Sec.~\ref{sec:q1}-\ref{sec:q3}).
%We then continue (Sec.~\ref{sec:eval}) to demonstrate its effectiveness in simulations and conclude by describing possible additional future work.

\begin{figure}[tb]
  \centering
  	\includegraphics[width=0.453\textwidth]{fig/env.png}
  	%\vspace{-2mm}
  \caption{
		Planning domain---Humanoid robot needs to use the ladder or the staircase to reach the top while avoiding collision with the obstacles and adhering to the physical stability constraints.
%  	\vspace{-15mm}
}
   	\label{fig:robot}
\end{figure}



%\section{Related work}
%\label{sec:related}
%

While our approach is general and can be incorporated with any motion-planning algorithm (see discussion in Sec.~\ref{sec:future}) it is especially suitable for search-based planning algorithms (see, e.g.,~\cite{CCL14}) that perform a systematic search guided by heuristic functions.
Specifically, we demonstrate its effectiveness for the case where the motion-planning algorithm is multi-heuristic A* (MHA*)~\cite{ASNHL16,NAL15} which we detail in Sec.~\ref{sec:mha}.
%MHA* is a search-based planning algorithm that takes in multiple, possibly inadmissible heuristic functions in addition to a single consistent admissible heuristic.
%It uses them simultaneously to search the configuration space in an A*-like manner that was shown to be both complete and ensures bounds on sub-optimality. 
%This allows the search to efficiently combine the guiding powers of different heuristic functions. 




After describing our approach at high-level (Sec.~\ref{sec:high}) we demonstrate how it can be applied to the case of MHA* (Sec.~\ref{sec:planning}).
We continue by showing the effectiveness of our planner (Sec.~\ref{sec:eval}).
Specifically, we show that this general approach allows to compute highly-constrained paths such as climbing stairs with little domain knowledge.
Without our approach, solving such problems require carefully-crafted domain-dependent heuristics. 
We conclude this paper with a discussion and an outline of possible future work (Sec.~\ref{sec:future}).


\section{Related work and algorithmic background}
\subsection{Motion planning for humanoid robots}
\label{sec:rel}
Humanoid robots, for which we demonstrate our approach, often have several dozens of degrees of freedom making planning a challenging task, especially when taking additional constraints into account such as stability and contact constraints.
One approach to plan the motion for such systems, is to use predefined, carefully chosen fixed gaits~\cite{KKKHKHAI04}. 
However, when the terrain is uneven, such planners are inadequate at computing stable motions~\cite{HBLHW08}.
Another approach is to reduce the search space by decomposing the degrees of freedom into functional groups such as locomotion and manipulation.
Then functional-specific algorithms such as footstep planning are applied to the low-dimensional space (see, e.g.,~\cite{CLCKHK05,KNKII01,PSBLY12,XCXZC09,KKNII02} for a partial list).
A high-dimensional planner is then used to ``track'' the plan generated in the low-dimensional space.


\subsection{Multi Heuristic A* (MHA*)}
\label{sec:mha}
Multi Heuristic A* (MHA*)~\cite{ASNHL16,NAL15} is a search-based planning algorithm that takes in multiple, possibly inadmissible heuristic functions in addition to a single consistent heuristic termed the \emph{anchor} heuristic.
It then uses the heuristic functions to simultaneously perform a set of weighted-A*~\cite{pohl1970first}-like searches.
Using multiple searches allows the algorithm to efficiently combine the guiding powers of the different heuristic functions. 

Specifically, for each search, MHA* uses a separate priority queue associated with each heuristic. 
The algorithm iterates between the searches in a structured manner that ensures bounds on sub-optimality. 
This can be done in a round-robin fashion, or using more 
sophisticated approaches that allow to automatically calibrate the weight given to each heuristic~\cite{PNAL15}.

Part of the efficiency of MHA* is due to the fact that the value of the cost-to-come (the $g$-value) computed for each state is shared between all the different searches\footnote{To be precise, Aine et al.~\cite{ASNHL16} define two variants of MHA*: Independent and Shared MHA* where the queues do not share and do share the $g$-values of states, respectively. In this paper when we use the term MHA*, it refers to the latter (shared) variant.}.
Sharing cost-to-come values between searches implies that if a better path to a state is discovered by any of the searches, the information is updated in all the
priority queues. 
Moreover, if one search ceases to make progress towards the goal (a state which we call ``stagnation region'' and which will be formally defined in Sec.~\ref{sec:planning}) it can use ``promising'' states found by other searches to escape this stagnation region (see also~\cite{HB12,I92}).
Furthermore, path sharing allows SMHA* to expand each state at most twice.
Finally, in graph search, heuristic functions give a principled way to identify when the planner ceases to make progress (see, e.g.,~\cite{VNL17}).


%heuristic depression
%regions, i.e., regions in the search space where the correlation between the heuristic values and the actual cost-to-go is
%weak
%
%Intuitively, a heuristic depression is a bounded region of the search space
%in which the heuristic is inaccurate with respect to the heuristic values of the states in
%the border of the region
%
%Ishida (1992) gave a constructive definition for \textbf{heuristic depressions}. The construction
%starts with a node s such that its heuristic value is equal to or less than those of the
%surrounding states. The region is then extended by adding a state of its border if all states
%in the resulting region have a heuristic value lower or equal than those of the states in the
%border. As a result, the heuristic depression D is a maximal connected component of states
%such that all states in the boundary of D h




\section{Algorithmic approach---user-guided planning}
\label{sec:high}

\algrenewcommand\algorithmicindent{.8em}
\begin{algorithm}[tb]
\caption{User-guided planning ($\A$)}
\label{alg:main}	
\begin{algorithmic}[1]
\small
\While{$\neg\A.$\texttt{is\_solution\_found()} } 
	\While{$\neg\A.$\texttt{is\_in\_stagnation\_region()}} 
		\State $\A.$\texttt{run()}
		\Comment{no user guidance}
	\EndWhile
%	
	\State {$g \leftarrow$ \texttt{get\_user\_guidance()}}
	\Comment{$\A$ is in a stagnation region}
	\State $\A.$\texttt{update\_user\_guidance($g$)}
	\Comment{account for guidance}
	\While{$\A.$\texttt{is\_in\_stagnation\_region()}}
		\State $\A.$\texttt{run()}
		\Comment{$\A$ uses guidance to escape stagnation region}
	\EndWhile

	\State $\A.$\texttt{update\_user\_guidance($\neg g$)}
	\Comment {remove  guidance}
\EndWhile
\end{algorithmic}
\end{algorithm}

To employ our planning framework, we assume that we are given a motion-planning algorithm $\A$ that is endowed with two non-standard procedures which are planner dependent.
The first, \texttt{is\_in\_stagnation\_region()}, 
identifies when it is in a \emph{stagnation region}, namely when $\A$'s search does not progress towards the goal. 
The second, \texttt{update\_user\_guidance()}, 
incorporates (or removes) the user guidance provided to $\A$. 

Equipped with these functions, we can describe our planning framework, detailed in Alg.~\ref{alg:main}.
The framework runs as long as no solution is found (line~1).
It runs the planner~$\A$ (lines~2-3) as long as it continuously makes progress towards the goal (namely, it is not in a stagnation region).
Once a stagnation region is identified, user guidance is invoked (line~4) and $\A$  is updated to make use of this guidance (line~5).
It is then run while using the guidance as long as it is still in the stagnation region (lines~6-7).
Once it escapes the stagnation region, $\A$ is updated to remove the guidance that was provided by the user (line~8).


\section{User-guided planning via MHA*}
\label{sec:planning}

We demonstrate our general planning framework described in Sec.~\ref{sec:high} for the case where the motion-planning algorithm~$\A$ is multi-heuristic A* (MHA*)~\cite{ASNHL16}.
We assume that MHA* has a set of possibly inadmissible heuristics in addition to the anchor heuristic. We will refer to these heuristics as \emph{baseline heuristics}.
The user guidance will be used to generate \emph{dynamic heuristics}.
We start (Sec.~\ref{sec:q1}-\ref{sec:q3}) by describing how we answer the three questions we posed in Sec.~\ref{sec:intro}.
We then continue to detail how they are used in our planning framework.
This implementation is slightly more complicated than that described in Alg.~\ref{alg:main} and is detailed in Sec.~\ref{sec:instantiation}.

\subsection{Invoking user guidance (Q1)}
\label{sec:q1}


\begin{figure*}[t]%
%\captionsetup{format = plain}
  \centering%
  \subfigure[]
  {
  \includegraphics[width=0.34\textwidth]{fig/local_min_detection_1.pdf}
  \label{fig:local_min1}
  }
  \hspace{-10mm}
%  \subfigure[]
%  {
%  \label{fig:local_min2}
%  \includegraphics[width=0.265\textwidth]{fig/local_min_detection_2.pdf}
%  }
%  \hspace{-10mm}
  \subfigure[]
  {
  \label{fig:local_min3}
  \includegraphics[width=0.34\textwidth]{fig/local_min_detection_3.pdf}
  }  
  \hspace{-10mm}
  \subfigure[]
  {
  \label{fig:local_min4}
  \includegraphics[width=0.34\textwidth]{fig/local_min_detection_4.pdf}
  }
  \vspace{-1mm}
  \caption{%
    Visualization of the way stagnation regions are detected.   
	\subref{fig:local_min1}~The heuristic value $h(s_i)$ (solid blue) has three local minima, $m_1, m_2$ and $m_3$ followed by three stagnation regions (light grey). Local minima $m_2$ is very small while~$m_3$ is not a local minimum per se, yet the progress made between consecutive steps is smaller than the predefined threshold~$\varepsilon$.
    %
    \subref{fig:local_min3}~The function $\kappa(i,\omega_1)$ (dashed green) returns the minimal value $h(s_i)$ attained over the past~$\omega_1$ iterations (referred to  as the ``recent history'').
    %
%    \subref{fig:local_min3}~
    The function $\kappa(i-\omega_2,\omega_1-\omega_2)$ (dotted red) returns the minimal value $h(s_i)$ attained over the beginning of the recent history.
    %
    \subref{fig:local_min4}~The difference between the two functions (solid purple) indicates if there was significant progress (i.e. more than $\varepsilon$) made at the end of the recent horizon when compared to the beginning of the recent history. 
    If not, then the planner detects a stagnation region (dark grey).
		Notice that the hysteresis parameters~$\omega_1$ and $\omega_2$ 
		(i)~induce a lag from the time that the stagnation region starts until it is detected,
		(ii)~allow to avoid detecting stagnation region~$r_2$.  
		}%

  \label{fig:filmstrip-local-min}%

  \vspace{-4.5mm}

\end{figure*}


The heuristic functions of search-based planning algorithms, such as MHA*, can be used to estimate in a principled manner when the planner is in a stagnation region (Alg~\ref{alg:main}, lines 2, 6). 
%Specifically, in such algorithms,  we proceed by iteratively choosing  the current-best state from a priority queue and computing all its successors. 
%
We suggest to identify when the planner is in a stagnation region as follows:
Let~$\Q$ be a priority queue 
ordered according to some heuristic function~$h(\cdot)$,
$s_i$ be the node expanded from~$\Q$ at the $i$'th iteration and $\omega_1, \omega_2$ be parameters such that $\omega_1 > \omega_2$.
%
We define 
$\kappa_\Q(i, \omega) = \min_{i-\omega \leq j \leq i} \{ h(s_j)\}$.
Namely, $\kappa_\Q(i, \omega)$ denotes the minimal value attained by $h$ in the past~$\omega$ states. 
%
\begin{definition}
A heuristic~$h$ associated with a queue~$\Q$ is defined to be in a stagnation region if 
$\kappa_\Q(i, \omega_1) \geq \kappa_\Q(i - \omega_2, \omega_1 - \omega_2) - \varepsilon$.
\end{definition}
\noindent Namely,~$\Q$ is in a stagnation region if looking at the previous~$\omega_1$ iterations, 
there was no reduction 
(by more than some threshold $\varepsilon$) 
in the minimum value of~$h$ 
in the last $\omega_2$ states expanded from $\Q$.

%\begin{definition}
%MHA* is defined to be in a local minimum if 
%all it's queues are in local minima.
%\end{definition}

Thus, our algorithm is given three additional parameters~$\omega_1, \omega_2$ and $\varepsilon$ 
and maintains  for each queue~$\Q$ the values~$\kappa_\Q(i, \omega_1)$ and $\kappa_\Q(i - \omega_2, \omega_1 - \omega_2)$.
Note that testing if a single queue is in a stagnation region takes $O(1)$ time.
For a visualization, see Fig.~\ref{fig:filmstrip-local-min}.

%As an aside, we note that our approach may have ``false detections''.
%As our heuristics may be incomplete, we can erroneously detect a stagnation region even if the planner will  actually make progress}

\subsection{Form of user guidance (Q2)}
\label{sec:q2}
We chose to obtain user guidance 
(Alg~\ref{alg:main}, line~4)
in the form of an intermediate configuration $\hat{q}$ that is used to guide the planner. We discuss alternative options in Sec.~\ref{sec:future}.

The framework includes a graphical user interface (GUI) (Fig.
~\ref{fig:gui}) capable of  depicting the robot and the workspace.
Once user guidance is invoked, 
a configuration in the stagnation region is obtained and the robot is placed in that configuration (as well as the start configuration and target region) in the GUI.
This allows the user to intuitively try and understand where the planner faces difficulty and how to guide it out of the stagnation region.
The user then suggests the guidance $\hat{q}$ by moving the robot's joints and end effectors.
The tool runs a state validity checker in the background which restricts the user from providing invalid configurations, e.g. with respect to collision, joint limits and stability.
Note that the user is \emph{not} required to be familiar with the search algorithm.

\begin{figure}[tb]
  \centering
  	\includegraphics[width=0.453\textwidth]{fig/gui.png}
  	%\vspace{-2mm}
  \caption{
		The graphical user interface used to provide guidance to the planner. The panel on the left hand side can be use to select different joint groups, move the joints around and pass the guidance to the planner. The interactive marker shown on the right hand side can be used to move the robot end effectors.
  	\vspace{-5mm}
}
   	\label{fig:gui}
\end{figure}

\subsection{Using user guidance (Q3)}
\label{sec:q3}

\begin{figure*}[t]%
%\captionsetup{format = plain}
  \centering%
  \subfigure[]
  {
  \includegraphics[width=0.225\textwidth]{fig/example_1.pdf}
  \label{fig:dynamic_heuristic1}
  }
  \subfigure[]
  {
  \label{fig:dynamic_heuristic2}
  \includegraphics[width=0.225\textwidth]{fig/example_2.pdf}
  }
  \subfigure[]
  {
  \label{fig:dynamic_heuristic3}
  \includegraphics[width=0.225\textwidth]{fig/example_3.pdf}
  }  
  \subfigure[]
  {
  \label{fig:dynamic_heuristic4}
  \includegraphics[width=0.225\textwidth]{fig/example_4.pdf}
  }
  \caption{%
    Algorithm progression.
    States popped from a priority queue are depicted using dark colors while states still in a queue are depicted by a light color.
    Start, target and user-guided states are depicted in purple with the letters \texttt{s}, \texttt{t}, \texttt{g}, respectively. 
    %
    In this example MHA* alternates between queues in a round-robin fashion. Furthermore, heuristics are inflated by a weight of $w=\infty$. Namely, the priority queues are ordered according to the heuristic-value of the states.
    %
	\subref{fig:dynamic_heuristic1}~MHA* starts with a single baseline heuristic (green) which is the Euclidean distance to goal and a local minimum is identified.
    %
	\subref{fig:dynamic_heuristic2}~User provides guidance and the algorithm automatically generates an additional heuristic (red) that drives the search towards the guidance (notice that the anchore heuristic continues to search the local minimum).
    %
	\subref{fig:dynamic_heuristic3}~After passing through the guidance, the additional heuristic (red) drives the search towards the goal.
    %
	\subref{fig:dynamic_heuristic4}~After the additional heuristic found states that are placed at the top of the priority queue of the anchor heuristic, the additional heuristic is deleted and the anchor heuristic drives the search towards the goal.
  }%
  \label{fig:filmstrip-dynamic_heuristic}%
  \vspace{-2.5mm}
\end{figure*}



We assume that MHA* has at least one baseline heuristic~$h_{\text{goal}}$ which approximates the cost to reach the goal from every state.
Furthermore, we assume that there exists a family of (possibly inadmissible) heuristic functions $\H$, such that for every configuration~$q$, there exists a heuristic $h_q \in \H$ where~$h_q(s)$ estimates the cost to reach $q$ from state $s$.
%%%%

Given user guidance in the form of a configuration $\hat{q}$, we dynamically generate a new heuristic $$
    \hat{h}(s)= 
\begin{cases}
    h_{\hat{q}}(s) + h_{\text{goal}}(\hat{q}),	& 
    		\text{if } \hat{q} \text{ is not an ancestor of } s,\\
    h_{\textbf{â€¢}{goal}}(s),            		& 
    		\text{if } \hat{q} \text{ is an ancestor of } s.
\end{cases}
$$
Namely,~$\hat{h}$ estimates the 
cost to reach the goal (via the term~$h_{\text{goal}}$) by passing through $\hat{q}$ (via the term $h_{\hat{q}}$). If the state was reached by passing through $\hat{q}$, then the value of $\hat{h}$ is simply the estimation of the cost to reach the goal.


Equipped with the heuristic $\hat{h}$, we add a new queue to the MHA* algorithm prioritized using the heuristic $\hat{h}$. %(Alg~\ref{alg:main}, line~4). 
States expanded using this queue will be biased towards $\hat{q}$ (see also~\cite{INL15} for more details on adding heuristics and queues dynamically to MHA*
and~\cite{NAL15} for more details on dealing with calibrating the different values used by different heuristic functions).
Note that in MHA*, nodes are shared between the different queues.
Thus, once a state has been found that can be used to get the planner out of the stagnation region, it will be expanded by the other queues using their heuristics.
Once this is detected 
%(Alg~\ref{alg:main}, line~8),
the newly-added queue is removed.

We note that we can add a dynamic queue for every baseline heuristic if there are more than one. However, for simplicity, in this work we use a single baseline heuristic and add one dynamically generated queue when the user provides guidance.

\subsection{User-guided MHA*}
\label{sec:instantiation}
We are now ready to describe how we apply our general framework of user-guided planning to the case of MHA*.
This differs slightly from the general approach described in Sec.~\ref{sec:high} due to our ability to identify which queue is in stagnation and to detect if the configuration~$\hat{q}$ (i.e., the guidance) was reached.

Specifically, if the baseline heuristic escaped a stagnation region but the configuration $\hat{q}$ was \emph{not} reached, we suspend the dynamic queue but do not discard it. 
This is done to first try reusing the last guidance before asking for a new one. 
When the planner will detect that is in a stagnation region, it will first resume the suspended dynamic heuristic (if one exists).

If the baseline heuristic escaped a stagnation region and the configuration~$\hat{q}$ was  reached it will no longer be useful again and hence will be discarded.
Finally, if the dynamic heuristic is in a stagnation region then it is discarded and the user will be queried for a new guidance. 

For pseudo-code describing the algorithm, describing the implementation of each specific function of our general pseudocode (Alg.~\ref{alg:main}), see Alg.~\ref{alg:instantiation}.
For a visualization of the way the algorithm progresses, see Fig.~\ref{fig:filmstrip-dynamic_heuristic}. Note that although for the illustrated example, the search happens to pass through the guidance, in general it is not a constraint in the framework. 
%
%Specifically, the planner can be in a local minima in the dynamically-generated queue that is used to escape the original local minima. 
%In such cases we request new guidance from the user and replace the previous guidance with the new one.

%\algrenewcommand\algorithmicindent{2em}
\begin{algorithm}[tb]
\caption{User-guided MHA*}
\label{alg:instantiation}	
\begin{algorithmic}[1]
\small
%\State \textbf{function} \texttt{is\_in\_stagnation\_region()}
\Function{\texttt{is\_in\_stagnation\_region()}}{}
 	\If {baseline heuristic not in stagnation}
		\State \textbf{return} true
	\Else
		\State \textbf{return} false
	\EndIf
\EndFunction
%	
\vspace{2mm}
%
\Function{\texttt{get\_user\_guidance()}}{}
%
	\If {exists suspended dynamic heuristic}
		\State \textbf{return}  {suspended dynamic heuristic}
	\Else
		\State{get new user guidance and add dynamic heuristic}
		\State \textbf{return}	{new dynamic heuristic}
	\EndIf
\EndFunction 
%	
\vspace{2mm}
%
\Function{\texttt{remove\_user\_guidance()}}{}
	\If {dynamic heuristic is in local minimum}
		\State {remove dynamic heuristic}
		\Comment{guidance is not useful}
	\Else 	\Comment{dynamic heuristic is not in local minimum}
		\If {states passed through guidance}
			\State {discard dynamic heuristic}
			\Comment{will not be useful in future}
		\Else
			\State {suspend dynamic heuristic}
			\Comment{may be useful in future}
		\EndIf
	\EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Evaluation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation }
\label{sec:eval}
We evaluated the performance of our planning framework on a 34-DOF WAREC humanoid robot~\cite{MHSetal15} 
which is constrained to maintain static stability at all times. The robot has four symmetric limbs each having seven revolute joints. The other six dimensions come from the pose of the robot with respect to some global frame of reference. 
In one of the experiments (Sec.~\ref{subsec:stairs}), we employ the recently-introduced adaptive dimensionality framework~\cite{GCBSL11,GSL12,GSL13}.
Roughly speaking,  it consists of two stages: an adaptive planning phase which attempts to plan in a low-dimensional space when possible and a tracking phase which plans in the high-dimensional space.
Our user-guided planner is integrated within the high-dimensional planner.
Specifically, the planner attempts to find a plan in the full-dimension configuration space of the robot in order to track the footstep plan generated in the planning phase. 

\subsection{Implementation details}
We used a set of motion primitives which are short kinematically feasible motion sequences to generate the actions, or the successors, of a state during the search. These primitives included clockwise and counter-clockwise rotation of individual joints. 
Specifically, four different types of motion primitives are used:
(i)~primitives for the free limbs of the robot i.e. the limbs whose end effectors are not constrained by any contact surface,  
(ii)~primitives to move the torso of the robot,
(iii)~primitives to latch onto the target end-effector poses
and
(iv)~primitives to latch onto the user-provided configuration once it is within a small threshold distance to the state being expanded.
Notice that motion primitives (ii) and (iii) require solving closed-chain inverse kinematics for the constrained limbs.

For each experiment we used a very small set of fairly generic heuristics. 
This is done to demonstrate that our approach allows to significantly reduce the engineering effort required in carefully crafting domain-specific heuristics. 
We conducted two experiments which largely differ in the nature of mobility and thus employ different baseline heuristic functions. 
The dynamic heuristic function in both the experiments is the Euclidean distance in the joint 34-DOF space.
The parameter values that we used consistently in the two experiments are $\omega_1 (200), \omega_2 (50)$ and $\varepsilon (50)$.
Finally in our final experiment, we show that while our approach uses several parameters, it is highly robust to the choice of parameters for our domain.

\subsection{Mounting onto a ladder}
The first task we considered was  mounting onto a ladder while starting from a standing position  (see Fig.~\ref{fig:ladder_plot}). 
The initial state of the robot here is a full-dimensional configuration. The goal state is defined as 6-DOF poses for all the four end effectors (hands and feet) of the robot. These poses are predefined contact positions on the ladder rungs which ensure a reasonable degree of robot stability. 
This is a challenging problem as the planner is required to compute the order in which each of these target contacts has to be reached. Moreover, the targets need to be approached in a certain direction to establish the desired contacts while avoiding collisions. 
The inability of heuristic functions to model such task-specific constraints introduce stagnation regions in the search. 
The baseline heuristic function that we used in this experiment is computed as the summation of four six-dimensional euclidean distances between each of the four end effectors and their respective target poses.


Results demonstrating the effectiveness of our framework are depicted in Fig.~\ref{fig:ladder_plot}
Specifically, we plot the heuristic value (a proxy to the algorithm's progress) as a function of the number of queue expansions.
For the same setting, we ran our algorithm with and without user guidance.
Namely, if a stagnation region was detected, we recorded the state of the planner and then continued to run it once without asking the user for guidance and once using our approach. This was done every time a stagnation region was detected. 
Results show that without guidance, the planner is not able to make any significant progress and the heuristic value does not change.
On the other hand, when guidance is given, then the algorithm escapes the stagnation region and resumes to make progress towards the goal.



\subsection{Climbing a staircase}
\label{subsec:stairs}
The second task we considered is climbing up a set of stairs while avoiding collision with obstacles (steps and handrails) as well as adhering to the physical constraints of the robot (see Fig.~\ref{fig:robot}). The initial state of the robot again is the full dimensional 34-DOF configuration of the robot but the goal state in this experiment is represented just as a cylindrical region which the robot needs to enter (depicted in Fig.~\ref{fig:stair_plot}).

In the absence of handrails the planner successfully finds a path to the goal without invoking the user for guidance. The handrails make the planning problem  harder. As the robot has to sway sideways during the stepping motion to maintain static stability, the handrails constrain its mobility.
To this end, we allow the user to provide guidance to the planner using the notion of support surfaces. 
We prespecify a set of valid contact surfaces (handrail cylinders in this experiment). When the user brings any of the robot hands within a threshold distance to a valid contact pose on a support surface, the GUI snaps the robot state to establish a valid support contact by solving the inverse kinematics for the respective limb. The planner incorporates this contact information while doing the stability evaluation for a state. 


Resultantly, when the user provides guidance, the dynamic heuristic guides the search to reach this user-provided state and continues to expand its successor states which moves the robot forward while maintaining the hand contact.
 
In the context of motion primitives, here we allow two types of motions for the robot torso, one with the hands in contact and the other that allow free motions for the robot arms. This helps the robot to let go of the handrail when it no longer needs the support. A single baseline heuristic is used in this experiment which assists the search with a general walking or stepping capability for the robot.
However, it is not designed to avoid obstacles or utilize support surfaces.



We conducted a similar experiment to the one described in Sec.~\ref{subsec:stairs} where we simulate the progress with and without user guidance for each depression region detected.
A similar trend can be seen in Fig.~\ref{fig:h_plot}. Note that for this experiment the plot depicts the instances where the dynamic heuristic also gets stuck in stagnation region because of the imperfections in the guidance but then eventually escapes it with additional guidances.

\begin{figure*}[t]%
%\captionsetup{format = plain}
  \centering%
  \subfigure[Mounting onto the ladder]
  {
  \includegraphics[width=0.375\textwidth]{fig/h_ladder.jpg}
  \label{fig:ladder_plot}
  \includegraphics[width=0.3\textwidth]{fig/ladder.png}
  }  
%
  \subfigure[Climbing up the staircase]
  {
  \includegraphics[width=0.37\textwidth]{fig/h_staircase.jpg}
  \label{fig:stair_plot}
  \includegraphics[width=0.3\textwidth]{fig/staircase.png}
  }

  \caption{%
    Progress of MHA* with and without user guidance---heuristic values as a function of the number of queue expansions.
		When a stagnation region is detected (red cross) in the baseline heuristic (cyan), a dynamic heuristic is generated (blue) until the stagnation region is escaped (green circle) or until a new stagnation region is detected (blue cross) in the dynamic heuristic.
		Plots depicting the baseline heuristic values when only a limited amount of guidance is given demonstrate that without guidance, the planner remains stuck in the stagnation region (we note that as MHA* is complete, it will eventually escape all such regions).}


  \label{fig:h_plot}%

  \vspace{-4.5mm}

\end{figure*}

%% stats
We evaluated the performance by running the experiments on the two environments. The results are shown in table~\ref{tab:stats}. In all the experiments the planner succeeds to reach the goal with the help of a user. The deviations in the experiments come from how good or bad the guidances were.

\begin{table}[t!]
\centering
\begin{tabular}{l|ccc}	
      & Ladder & Staircase\\ 
        \hline
            Success Rate(percent) & 100 & 100\\
            Mean planning time(s) & 113 $\pm$ 36 & 101 $\pm$ 17.5\\
            Mean total time(s) & 222 $\pm$ 55 & 246 $\pm$ 53.5\\
       Mean state expansions & 708 $\pm$ 189 & 1219 $\pm$ 242\\
      Mean num of guidances & 5.5 $\pm$ 0.85 & 8 $\pm$ 2\\
      Mean time per guidance(s) & 20 $\pm$ 3.6 & 18.5 $\pm$ 3\\
\end{tabular}
\caption{Experimental results for the the staircase and ladder scenarios averaged over 10 trials}\label{tab:stats}
\vspace{-10mm}
\end{table}

\subsection{Robustness to algorithmic parameters}
We introduced three parameters in section Sec.~\ref{sec:q1} i.e ~$\omega_1, \omega_2$ and $\varepsilon$ which govern where the user guidance will be invoked. We can show that our approach is not very sensitive to the change in these parameters and thus they don't require fine tuning. The results presented in Fig. ~\ref{fig:h_plot} are for some nominal values of the parameters. 

For the experiments that we conducted, the results don't vary with changing $\omega_1$ because the heuristic functions that we used don't show dips as illustrated in the hypothetical illustration in Fig.~\ref{fig:filmstrip-local-min} but in general, such a trend can occur in an arbitrarily inadmissible heuristic. $\varepsilon$ is a domain dependent parameter and its magnitude should be set relative to the scale of the corresponding heuristic function. For instance if we use $n$ baseline heuristics, then the value of $\varepsilon$ for each of these heuristics should be proportional to the scale of that heuristic. Having said that one can fix $\varepsilon$ and tune the parameter $\omega_2$ until you get the desired behaviour, as both of them are correlated and measure the rate of progress being made by a heuristic. 

To show robustness to $\omega_2$, we linearly swept its value over a window centred at the nominal value used for experiments and checked how many of the stagnation region detections matched with the nominal results. Fig. ~\ref{fig:robustness} shows the evaluation for the two experiments. For the values of $\omega_2$ where the matching ratio is 1, the planner would have invoked the user exactly for the same stagnation regions as the ones for which the guidance was called using the nominal parameters.

\begin{figure}[t]%
%\captionsetup{format = plain}
  \centering%
  \hspace{-2mm}
  \subfigure[\footnotesize Mounting onto the ladder]
  {
  \includegraphics[width=0.20\textwidth]{fig/ladderly.png}
  
  \label{fig:robust_ladder}
  }
%
  \subfigure[\footnotesize Climbing up the staircase]
  {
  \includegraphics[width=0.20\textwidth]{fig/stairly.png}
  \label{fig:robust_stair}
  }

  \caption{%
    The plot shows the ratio of the number stagnation region detections matched to the total number of regions detected by the nominal parameter values, for $\omega_2$ values swept around the nominal value (50) by $\pm$ 40 expansions with a step of 5. 
  \vspace{-5mm}
}
   	\label{fig:robustness}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Discussion and future work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion and future work}
\label{sec:future}

\subsection{Discussion}
In Sec.~\ref{sec:eval} we demonstrated how using user guidance allows to solve highly-constrained motion-planning in high-dimensional spaces with only simple baseline heuristics.
An alternative approach would be to add domain-dependent carefully-crafted heuristics~\cite{V17} which allow to faster solve the same problems completely autonomously.

When a new type of problem is encountered 
(say, climbing a ladder, crawling on uneven terrain etc.)
we can either design additional heuristics to tackle this problem or shift the burden to the user to provide guidance in an online fashion.
If our problem requires planning in multiple, diverse types of domains this problem is accentuated---should we  use a large arsenal of heuristics that can address each domain or should we have a small number of baseline heuristics that will (roughly) address all domains and rely on user guidance when these baseline heuristics fail?
There is no clear answer to this question and our approach simply offers a general alternative to existing approaches.


\subsection{Future work}
While providing promising initial results, our framework is far from being complete.
We are interested in experimenting with alternative forms of user guidance such as providing a \emph{constrained sub-manifold} of the configuration space which can be more informative for the planner instead of providing it with a single joint configuration and could potentially reduce the number of user invocations. 
Finally, once a guide is given, we want our planner to be able to \emph{generalize} the guidance obtained to future stagnation regions that are similar in nature to the ones encountered (e.g., climbing up multiple stairs).

Finally we are interested in implemented our approach using sampling-based planners. Here, once the user will provide guidance, it can be used to bias the sampling procedure. 
An open challenge remains how to automatically detect that the planner is not progressing toward the goal.


%\newpage

%\bibliographystyle{plainnat}
\bibliographystyle{named}
%\bibliographystyle{abbrv}
\bibliography{bibliography}

\end{document}
